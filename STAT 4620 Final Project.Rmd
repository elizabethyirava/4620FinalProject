---
title: "STAT 4620 Project"
author: "Dominic Blackston, Austin Usher, Elizabeth Yirava, Megan Zhao"
date: "2024-11-22"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Read in packages
```{r, message = FALSE}
library(tidyverse)
```


### Read in dataset
```{r}
train = read.csv('train.csv')
test = read.csv('test.csv')
```

# EDA

## Data Exploration

```{r}
dim(train)
dim(test)
```
Looking at the dimensions tells us that the training dataset has 728 rows and 37 columns. The testing dataset has 484 rows and 37 columns. This dataset has a lot of parameters, suggesting a need to reduce its dimensionality.

```{r}
train %>% 

  summarize(across(everything(), ~ sum(is.na(.)), .names = "missing_{.col}")) 

test %>% 

  summarize(across(everything(), ~ sum(is.na(.)), .names = "missing_{.col}")) 
```

157 rows are missing Metadata.Publishers in the train dataset; 107 rows are missing Metadata.Publishers in the test dataset.  After doing research, we found that many of the null columns had publishers that were already included in the dataset (for example, Rock Band had no publisher listed but it should be EA, which is already a value for many rows in that column). After discussion, it was decided to eliminate this column due to its unreliability. All but the "AllPlayStyles" columns will be removed due to those columns having a large number of missing values. The AllPlayStyles columns will have null values filled with median values. The data appears to be accurate other than the aforementioned issues.

## Data Cleaning

## Remove features

We removed a majority of the Length columns due to many missing values. We also removed title due to it being a variable that is always distinct. We removed publisher due to the reasons listed previously.
```{r}
train_subset = train[c('Features.Handheld.', 'Features.Max.Players', 'Features.Multiplatform.', 'Features.Online.', 'Metadata.Genres', 'Metadata.Licensed.', 'Metadata.Sequel.', 'Metrics.Review.Score', 'Metrics.Sales','Metrics.Used.Price', 'Release.Console', 'Release.Rating', 'Release.Re.release.', 'Release.Year', 'Length.All.PlayStyles.Average', 'Length.All.PlayStyles.Leisure', 'Length.All.PlayStyles.Median')]
test_subset = test[c('Features.Handheld.', 'Features.Max.Players', 'Features.Multiplatform.', 'Features.Online.', 'Metadata.Genres', 'Metadata.Licensed.', 'Metadata.Sequel.', 'Metrics.Review.Score', 'Metrics.Sales','Metrics.Used.Price', 'Release.Console', 'Release.Rating', 'Release.Re.release.', 'Release.Year', 'Length.All.PlayStyles.Average', 'Length.All.PlayStyles.Leisure', 'Length.All.PlayStyles.Median')]
```

### Fill in null values

```{r}
#Training
median_value_avg <- median(train_subset$Length.All.PlayStyles.Average[train_subset$Length.All.PlayStyles.Average != 0], na.rm = TRUE)

train_subset$Length.All.PlayStyles.Average[train_subset$Length.All.PlayStyles.Average == 0] = median_value_avg

median_value_leisure <- median(train_subset$Length.All.PlayStyles.Leisure[train_subset$Length.All.PlayStyles.Leisure != 0], na.rm = TRUE)

train_subset$Length.All.PlayStyles.Leisure[train_subset$Length.All.PlayStyles.Leisure == 0] = median_value_leisure

median_value_median <- median(train_subset$Length.All.PlayStyles.Median[train_subset$Length.All.PlayStyles.Median != 0], na.rm = TRUE)

train_subset$Length.All.PlayStyles.Median[train_subset$Length.All.PlayStyles.Median == 0] = median_value_median

#Testing
median_value_avg <- median(test_subset$Length.All.PlayStyles.Average[test_subset$Length.All.PlayStyles.Average != 0], na.rm = TRUE)

test_subset$Length.All.PlayStyles.Average[test_subset$Length.All.PlayStyles.Average == 0] = median_value_avg

median_value_leisure <- median(test_subset$Length.All.PlayStyles.Leisure[test_subset$Length.All.PlayStyles.Leisure != 0], na.rm = TRUE)

test_subset$Length.All.PlayStyles.Leisure[test_subset$Length.All.PlayStyles.Leisure == 0] = median_value_leisure

median_value_median <- median(test_subset$Length.All.PlayStyles.Median[test_subset$Length.All.PlayStyles.Median != 0], na.rm = TRUE)

test_subset$Length.All.PlayStyles.Median[test_subset$Length.All.PlayStyles.Median == 0] = median_value_median
```

### Check for duplicated values
```{r}
train_subset = train_subset[!duplicated(train_subset),]
test_subset = test_subset[!duplicated(test_subset),]
dim(train_subset)
dim(test_subset)
```
There are no duplicate values since the dimensions did not change.

### Collinearity

```{r}
corrmatrixtrain <- train %>%
  select(where(is.numeric)) %>%
  cor(use = "pairwise.complete.obs")
corrmatrixtest <- test %>%
  select(where(is.numeric)) %>%
  cor(use = "pairwise.complete.obs")

corrmatrixtrain[lower.tri(corrmatrixtrain)] <- NA
corrmatrixtest[lower.tri(corrmatrixtest)] <- NA

corrdftrain <- as.data.frame(as.table(corrmatrixtrain))
corrdftest <- as.data.frame(as.table(corrmatrixtest))

corrtrain80 <- corrdftrain %>%
  filter(Freq > 0.8 & Freq < 0.99999)
corrtest80 <- corrdftest %>%
  filter(Freq > 0.8 & Freq < 0.99999)

corrtrain80 %>%
  arrange(desc(Freq))
corrtest80 %>%
  arrange(desc(Freq))

head(corrtrain80, 5)
head(corrtest80, 5)
```
The numerical Play Length variables we can see are highly correlated with one another, which is to be expected considering game design having shared underlying factors and tendencies of each player. This suggests that should be removed from out model

### EDA Insights for Modeling

```{r}
# Correlation heatmap for numeric variables
library(ggcorrplot)

numeric_data <- train_subset[sapply(train_subset, is.numeric)]
cor_matrix <- cor(numeric_data, use = "complete.obs")

cor_matrix = round(cor_matrix,1)

# Plot heatmap with larger size and improved readability
ggcorrplot(cor_matrix, 
           lab = TRUE,        
           lab_size = 2,      
           tl.cex = 5,       
           title = "Correlation Heatmap", 
           ggtheme = ggplot2::theme_minimal()) +
  theme(
    plot.title = element_text(size = 10, face = "bold"),
    axis.text = element_text(size = 4)                  
  )

# Extract correlations of 'Metrics.Sales' with all other numeric variables
sales_correlations <- cor_matrix["Metrics.Sales", ]


```


Because many variables have very small correlation with the Sales variable both Lasso and Ridge would be useful to diminish the impact of non important variables. Lasso would work best to selected the needed features and to simplify the model as some coefficients are set to 0. Ridge does not to feature selection so would not be as ideal.

### Types of Variables

```{r}
# Check the structure of the data
str(train_subset)

# Numeric, Factor, and Character Variable Count Without %>%
numeric_vars <- sum(sapply(train_subset, is.numeric))
factor_vars <- sum(sapply(train_subset, is.factor))
character_vars <- sum(sapply(train_subset, is.character))

# Create a summary table for variable types
var_summary <- data.frame(
  numeric_vars = numeric_vars,
  factor_vars = factor_vars,
  character_vars = character_vars
)

# Print the summary table
print(var_summary)

# Summary for each variable in the dataset
summary(train_subset)

```

Sales shows a right-skewed distribution indicating few games achieve very high sales while the majority have fewer sales. Review scores also display a broad variation which could be useful in predicting sales. Features such as number of players, multiplatform, sequels, and online capabilities could also be helpful in predicting sales. Some game play styles have very large outliers which could affect prediction.


### Final variable selection

```{r}
train_subset = train_subset[c('Features.Handheld.', 'Features.Max.Players', 'Features.Multiplatform.', 'Features.Online.', 'Metadata.Genres', 'Metadata.Licensed.', 'Metadata.Sequel.', 'Metrics.Review.Score', 'Metrics.Sales','Metrics.Used.Price', 'Release.Console', 'Release.Rating', 'Release.Re.release.', 'Release.Year', 'Length.All.PlayStyles.Median')]

test_subset = test_subset[c('Features.Handheld.', 'Features.Max.Players', 'Features.Multiplatform.', 'Features.Online.', 'Metadata.Genres', 'Metadata.Licensed.', 'Metadata.Sequel.', 'Metrics.Review.Score', 'Metrics.Sales','Metrics.Used.Price', 'Release.Console', 'Release.Rating', 'Release.Re.release.', 'Release.Year', 'Length.All.PlayStyles.Median')]
```
Values used in the models before further evaluation.

## Final dataset summary

```{r}
summary(train_subset)
summary(test_subset)
```
DISCUSS THIS

# Model Building

## LASSO

### Motivation

### Mathematical Description

### Model Assumptions

### Model Building and Validation (compare testing with training)

## Ridge

### Motivation

### Mathematical Description

### Model Assumptions

### Model Building and Validation (compare testing with training)

## PCA

### Motivation

### Mathematical Description

### Model Assumptions

### Model Building and Validation (compare testing with training)

## PLS

### Motivation

### Mathematical Description

### Model Assumptions

### Model Building and Validation (compare testing with training)






